# montrs-llm

The AI-First logic engine for MontRS. This package provides the systems for generating AI-readable project snapshots, versioned error tracking, and curated tool specifications.

## Overview

MontRS is designed to be "model-first," meaning it provides standardized, machine-readable metadata and state information that AI models (like Gemini, GPT, or Claude) can use to understand and build with the framework. `montrs-llm` is the primary package responsible for this capability.

## Key Features

- **Project Snapshots**: Generates `llm.json` (and YAML/TXT versions) containing the entire project structure, modules, routes, and documentation.
- **Versioned Error Tracking**: Manages a `.llm/errorfiles/` directory where errors are recorded, versioned, and tracked over time.
- **Error Resolution Diffing**: When an error is resolved, `montrs-llm` creates a new version of the error record including a diff of the fix, which serves as training data for AI models.
- **Tools Specification**: Curates `tools.json` which defines the available CLI commands and package capabilities as AI-native tool/function calls.

## Integration

`montrs-llm` is used primarily by the MontRS CLI to:
1. Autogenerate the `.llm/` folder on every interaction.
2. Record detailed error reports when builds or tests fail.
3. Provide a unified interface for AI models to query the project state.

## AI Usage Guide

AI models can use the files generated by this package to:
- **Map the codebase**: Read `llm.json` to understand the file structure and module relationships.
- **Debug errors**: Access `errorfiles/` to see historical errors, their context, and how similar errors were fixed in the past.
- **Execute tools**: Use `tools.json` to understand which CLI commands can be called to perform tasks (build, test, generate).

## Metadata

- **Subsystem**: `llm`
- **AI-Native**: Yes
- **Version**: 0.1.0
